Data Quality Testing: "Active Vessels" (RightShip)

I. Overview
1. Objectives
The Data Quality Analyst (QA) is responsible for auditing the historical data of active vessels. This involves verifying the accuracy and reliability of the data pipeline to ensure maritime safety and mitigate operational risks that could impact business performance.
The testing scope focuses on a data pipeline comprising three primary sources:
- Vessel Registry (Master Data) 
- Voyage History 
- Inspection Records

2. Methodology & Approach
- Testing is performed on the vessels table, which serves as the Master Data containing comprehensive vessel information, uniquely identified by an IMO number. Key attributes include vessel_id, vessel_name, imo, and vessel_status.
- Inspection Data: Since the "Inspection" sheet lacks timestamp data, validation relies on inspection_source and is_active_inspection_source to verify the source's validity and status. The inspection_type column is used to ensure business logic alignment.
- Voyage Data: The "Daily Voyage" sheet aggregates vessel movements by IMO, tracking the earliest and most recent voyage timestamps.

II. Comprehensive Testing Framework
Testing is conducted across multiple layers to ensure end-to-end data integrity and facilitate efficient error detection.

2.1. Unit Testing
Executed at the initial stage to validate fundamental data attributes. This includes:
- Data Integrity: Checking data types, field presence, and uniqueness of identifiers.
- Validation Rules: For example, in the vessels sheet, a vessel_id of -3 was identified. Since IDs cannot be negative, such records are flagged for removal.
- Uniqueness: IMO number must be unique. Sample data analysis confirmed no duplicate IMOs in the current set, validating the remaining records.
- Completeness: Active vessels must have populated values for vessel_status and vessel_status_group.

2.2. Integration Testing
This phase verifies the relationships and linkages between vessel registration, voyage history, and inspection records.
- Key Mapping: Validating links between vessels and Daily Voyage tables via imo and vessel_id.
- Consistency Check: A discrepancy was found where only 5 IMOs existed in Daily Voyage compared to 9 valid IMOs in the vessels table. Furthermore, only 2 of those 5 IMOs matched the master list, indicating significant data gaps or inconsistencies.
- Requirement: Every IMO in "Daily Voyage" must exist in the "vessels" table, and every active vessel should have at least one recorded voyage.

2.3. System Testing
System testing validates the end-to-end process against business rules to define "Active Vessels".
- Activity Verification: Confirming status based on recent voyages and excluding decommissioned or inactive vessels.
- Maintenance Logic: Estimating downtime and return-to-service dates for vessels undergoing repairs.
- Anomaly Detection: Testing identified 5 vessels marked as "In Service" that lacked any voyage history in the Daily Voyage sheet. This contradicts the business expectation that active vessels must have at least one voyage record, signaling potential data entry or synchronization issues.

2.4. Data Quality Testing
Ensures all system components are standardized and consistent following core testing phases.
- Standardization: Validating null values, handling outliers, and normalizing timestamps to UTC.
- Classification: Aligning vessel types with RightShip standard classifications.
Outcome: Current audits indicate the system is standardized, enhancing reporting reliability and reducing analytical risk.

2.5. Regression Testing
Ensures that updates or bug fixes do not compromise existing logic or data contracts.
- Validation: Comparing metrics pre- and post-modification, focusing on record counts, voyage coverage, and DQ exceptions.
- CDC Check: Verifying sensitive data for Change Data Capture (CDC) processes.

2.6. User Acceptance Testing (UAT)
Final verification to ensure the data output meets all defined business requirements.

III. Defect Management & Reporting
- Identification: Defects found during Unit, Integration, or UAT are logged and assessed for business impact.
- Root Cause Analysis (RCA): QA teams collaborate with Engineering to investigate issues using SQL validation and schema analysis.
- Resolution & Verification: Once fixed, QA re-runs relevant test cases to verify the solution.
- Closure: Bugs are closed only after successful regression testing ensures no side effects.

Case Study: Logic Inconsistency
- Issue: Vessels flagged as "In Service" but missing voyage history in Daily Voyage.
- Technical Audit: A LEFT JOIN was performed between the vessels table (filtered for vessel_status = 'In Service') and the Daily Voyage table to isolate active vessels with null voyage records.

IV. Conclusion
The whole process is based on the principle: 'Verify early, Verify often'. Detecting logic errors right from the Integration Test step helps RightShip save the cost of repairing data on Production and maintain its reputation for safety in the maritime industry.
